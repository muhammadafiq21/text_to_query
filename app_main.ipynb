{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYSTEM MASSAGE (PROMPT FOR OPENAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_PROMPT = \"\"\"You are an AI assistant that is able to convert natural language into a properly formatted SQL query.\n",
    "\n",
    "The database you will be querying is called \"sakila\". Here is the schema of the database:\n",
    "{schema}\n",
    "\n",
    "You must always output your answer in JSON format with the following key-value pairs (without the \"json\" text at the beginning of the output):\n",
    "{{- \"chain of thought\": the reasoning or story behind the generated query\n",
    "- \"query\": the SQL query that you generated\n",
    "- \"error\": an error message if the query is invalid, or null if the query is valid}}\n",
    "\n",
    "here is the correct output, dont use anything other than this following output example:\n",
    "\n",
    "{{-\"chain_of_thought\": \"The user is asking for the description of all tables in the sakila database. To achieve this, we would typically use the 'DESCRIBE' or 'SHOW COLUMNS FROM' command in SQL for each table. However, since the user is asking for the description of all tables, we would use the 'SHOW TABLES' command to get the list of tables and then describe each one. But as an AI, I can only generate a single SQL query at a time, so I will provide the SQL command to list all the tables, which is the first step in the process.\"\n",
    "-\"query\": \"SELECT title, length FROM film ORDER BY length DESC LIMIT 1;\",\n",
    "-\"error\": null}}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = xxx\n",
    "openai.api_base = xxx\n",
    "openai.api_version = xxx\n",
    "openai.api_key = xxx\n",
    "\n",
    "def get_completion_from_messages(system_message, user_message, model=\"gpt-4\", temperature=0, max_tokens=500) -> str:\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': f\"{user_message}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTING TO DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(\n",
    "  host=\"xx\",\n",
    "  user=\"xx\",\n",
    "  password=\"xx\",\n",
    "  database = 'xx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor=cnx.cursor()\n",
    "query=(\"SELECT  TABLE_NAME, COLUMN_NAME, DATA_TYPE, COLUMN_KEY FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA='sakila';\")\n",
    "cursor.execute(query)\n",
    "data = []\n",
    "for row in cursor:\n",
    "  data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data, columns=cursor.column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass context of database into the prompt\n",
    "formatted_system_message = OPENAI_PROMPT.format(schema=df)\n",
    "\n",
    "# user text input\n",
    "user_message = \"what is the shortest movie?\"\n",
    "\n",
    "#Â generate query using openai\n",
    "response = get_completion_from_messages(formatted_system_message, user_message)\n",
    "\n",
    "# extract the output with re\n",
    "pattern = r'\\{(?:.|\\n)+\\}'\n",
    "\n",
    "# Use re.search() to find the first occurrence of the pattern in the text\n",
    "match = re.search(pattern, response)\n",
    "\n",
    "# If a match is found, extract the matched text\n",
    "if match:\n",
    "    extracted_text = match.group()\n",
    "\n",
    "json_response = json.loads(extracted_text)\n",
    "json_response['query']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTING QUERY IN DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor=cnx.cursor()\n",
    "querys=(json_response['query'])\n",
    "cursor.execute(querys)\n",
    "data = []\n",
    "for row in cursor:\n",
    "  data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data, columns=cursor.column_names)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
